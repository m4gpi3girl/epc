{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaeeda88-a111-4fde-b1c7-a272ffc66b88",
   "metadata": {},
   "source": [
    "<h1>Import Packages</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e14ef272-5152-4d35-bda8-ebaa0a0d7931",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ff509f-625c-4f56-a42e-f51d51d19118",
   "metadata": {},
   "source": [
    "<h1>Combine EPC Files into 1 Dataframe</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ec29ea1-d89d-4e4a-b228-f5e1a1ea396d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_directory = r\"C:\\Users\\Elisha.Zissman\\OneDrive - Social Investment Business\\Desktop\\epc_docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e24728a9-ee9a-408e-b2e4-4d01d0c8a811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function to extract\n",
    "\n",
    "def extract_certificates_to_dataframe(folder_path): \n",
    "\n",
    "    certificates_file = os.path.join(folder_path, 'certificates.csv') \n",
    "\n",
    "    if os.path.exists(certificates_file): \n",
    "\n",
    "        df = pd.read_csv(certificates_file)  # Assuming certificates file is CSV, adjust accordingly \n",
    "\n",
    "        return df \n",
    "\n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8cd9869-a2be-488b-b77b-b63ce8663a66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elisha.Zissman\\AppData\\Local\\Temp\\ipykernel_18156\\646180137.py:9: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(certificates_file)  # Assuming certificates file is CSV, adjust accordingly\n"
     ]
    }
   ],
   "source": [
    "dataframes = [] \n",
    "\n",
    "for folder_name in os.listdir(main_directory): \n",
    "\n",
    "    folder_path = os.path.join(main_directory, folder_name) \n",
    "\n",
    "    if os.path.isdir(folder_path): \n",
    "\n",
    "        df = extract_certificates_to_dataframe(folder_path) \n",
    "\n",
    "        if df is not None: \n",
    "\n",
    "            dataframes.append(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07515bae-21fc-407c-b49b-dfe7c56b5a89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_dataframe = pd.concat(dataframes, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4604fdd-edb5-4a03-b881-3c8fd3fd8fa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epc = combined_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832a8b94-5ec2-41b6-809f-3cd7c6ae8966",
   "metadata": {},
   "source": [
    "<h2>Checkpoint - Initial Download</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1429ef2-1892-499f-adc9-633f8476d908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the number of rows\n",
    "num_rows = len(epc)\n",
    "\n",
    "epc['INSPECTION_DATE'] = pd.to_datetime(epc['INSPECTION_DATE'])\n",
    "\n",
    "# Find the oldest and newest dates\n",
    "oldest_date = epc['INSPECTION_DATE'].min()\n",
    "newest_date = epc['INSPECTION_DATE'].max()\n",
    "\n",
    "# Create the message\n",
    "message1 = f'contains {num_rows} rows. Oldest Date: {oldest_date}. Newest Date: {newest_date}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d2d2d46-a55a-406e-b879-1b1141e89be2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains 1308301 rows. Oldest Date: 2000-02-10 00:00:00. Newest Date: 2023-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(message1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a12627-8e06-4fd8-ba3c-7967d137cbb9",
   "metadata": {},
   "source": [
    "<h1>Preparing Geography Information</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "584adb89-1306-4612-a351-f979f11ece39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elisha.Zissman\\AppData\\Local\\Temp\\ipykernel_18156\\2495203614.py:1: DtypeWarning: Columns (26,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  nspl = pd.read_csv('nspl_21.csv')\n"
     ]
    }
   ],
   "source": [
    "nspl = pd.read_csv('nspl_21.csv')\n",
    "rural_urban = pd.read_csv('rural_urban.csv')\n",
    "imd_dec = pd.read_excel('IMD 2019.xlsx', sheet_name=1)\n",
    "conv = pd.read_csv('lsoa11 to lsoa21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40ec38b9-ec27-4426-9557-0ae213018ed4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv = conv.rename(columns={'LSOA11CD':'lsoa11', 'LSOA21CD':'lsoa21'})\n",
    "conv = conv.drop(columns=['ObjectId',\n",
    " 'LSOA11NM',\n",
    " 'LSOA21NM',\n",
    " 'LAD22CD',\n",
    " 'LAD22NM',\n",
    " 'LAD22NMW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "798f8747-850d-4c99-883b-f9ac045f4d5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epc = epc.rename(columns={'POSTCODE':'pcds'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e00cf39-9154-4fbf-b891-db2381f24a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nspl = nspl.drop(columns=['pcd',\n",
    " 'pcd2',\n",
    " 'dointr',\n",
    " 'doterm',\n",
    " 'usertype',\n",
    " 'oseast1m',\n",
    " 'osnrth1m',\n",
    " 'osgrdind',\n",
    " 'oa21',\n",
    " 'cty',\n",
    " 'ced',\n",
    " 'laua',\n",
    " 'ward',\n",
    " 'nhser',\n",
    " 'ctry',\n",
    " 'pcon',\n",
    " 'ttwa',\n",
    " 'itl',\n",
    " 'npark',\n",
    " 'msoa21',\n",
    " 'wz11',\n",
    " 'sicbl',\n",
    " 'bua22',\n",
    " 'ru11ind',\n",
    " 'oac11',\n",
    " 'lat',\n",
    " 'long',\n",
    " 'lep1',\n",
    " 'lep2',\n",
    " 'pfa',\n",
    " 'icb', 'imd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4cb691e-c860-42a3-917d-897846886612",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rural_urban = rural_urban.rename(columns={'LSOA11CD':'lsoa11'})\n",
    "rural_urban = rural_urban.drop(columns=['FID', 'LSOA11NM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59daec44-2e1f-4845-bc08-8f392b2a574c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imd_dec = imd_dec.rename(columns={'LSOA code (2011)':'lsoa11'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633994d0-09d1-45c6-b24d-9c7419f2b79d",
   "metadata": {},
   "source": [
    "<h1>Merging Dataframes</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "697a8fff-ded5-4999-9dfa-4e4636676601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge with postcode lookup\n",
    "\n",
    "merged_df = epc.merge(nspl, on='pcds', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c2442c-403e-4b01-a3cb-2572a3d0829e",
   "metadata": {},
   "source": [
    "<h2>Checkpoint - NSPL Merge</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2634974-7435-4ee1-b2e7-e48026f6b14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains 1308301 rows. Oldest Date: 2000-02-10 00:00:00. Newest Date: 2023-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of rows\n",
    "num_rows = len(merged_df)\n",
    "\n",
    "merged_df['INSPECTION_DATE'] = pd.to_datetime(merged_df['INSPECTION_DATE'])\n",
    "\n",
    "# Find the oldest and newest dates\n",
    "oldest_date = merged_df['INSPECTION_DATE'].min()\n",
    "newest_date = merged_df['INSPECTION_DATE'].max()\n",
    "\n",
    "# Create the message\n",
    "message2 = f'contains {num_rows} rows. Oldest Date: {oldest_date}. Newest Date: {newest_date}'\n",
    "print(message2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e01a470-5bbb-4237-a21d-7a3217da12fa",
   "metadata": {},
   "source": [
    "<h1>Removing non England</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df9ae217-bc53-44c2-b0de-1b2280661639",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove non-england regions\n",
    "\n",
    "merged_df = merged_df[merged_df['rgn'].notna() & merged_df['rgn'].str.startswith('E', na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0998f1a2-26e8-4dc2-93b1-9914146444fe",
   "metadata": {},
   "source": [
    "<h2>Checkpoint - Removing Non-England</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "997edf84-598d-4195-b2a7-5c69ad6b6cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains 1246391 rows. Oldest Date: 2000-02-10 00:00:00. Newest Date: 2023-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of rows\n",
    "num_rows = len(merged_df)\n",
    "\n",
    "merged_df['INSPECTION_DATE'] = pd.to_datetime(merged_df['INSPECTION_DATE'])\n",
    "\n",
    "# Find the oldest and newest dates\n",
    "oldest_date = merged_df['INSPECTION_DATE'].min()\n",
    "newest_date = merged_df['INSPECTION_DATE'].max()\n",
    "\n",
    "# Create the message\n",
    "message3 = f'contains {num_rows} rows. Oldest Date: {oldest_date}. Newest Date: {newest_date}'\n",
    "print(message3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c3a3c4-e34f-48b1-8555-b2ebb13ad58a",
   "metadata": {},
   "source": [
    "<h1>Converter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f9f822a-4ba2-4415-9f86-b6b6196bc4f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(conv, on='lsoa21')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52824c1e-c2b5-4af7-8c74-69c404097a8f",
   "metadata": {},
   "source": [
    "<h2>Checkpoint - Merging with Converter file</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41bb5d1a-1c37-4062-8963-8cd39fef6567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains 1202805 rows. Oldest Date: 2000-02-10 00:00:00. Newest Date: 2023-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of rows\n",
    "num_rows = len(merged_df)\n",
    "\n",
    "merged_df['INSPECTION_DATE'] = pd.to_datetime(merged_df['INSPECTION_DATE'])\n",
    "\n",
    "# Find the oldest and newest dates\n",
    "oldest_date = merged_df['INSPECTION_DATE'].min()\n",
    "newest_date = merged_df['INSPECTION_DATE'].max()\n",
    "\n",
    "# Create the message\n",
    "message4 = f'contains {num_rows} rows. Oldest Date: {oldest_date}. Newest Date: {newest_date}'\n",
    "print(message4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ad9976-8d7e-4581-a577-89dcec900e84",
   "metadata": {},
   "source": [
    "<h1>Urban Rural</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b7b1e60-b652-4915-baa4-d2e170a09bae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(rural_urban, on='lsoa11', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d50d3-4a2a-4154-b366-52bfbdea8269",
   "metadata": {},
   "source": [
    "<h2>Checkpoint - Converter</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3b2921a-a849-4563-b012-867688d3e082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains 1202805 rows. Oldest Date: 2000-02-10 00:00:00. Newest Date: 2023-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of rows\n",
    "num_rows = len(merged_df)\n",
    "\n",
    "merged_df['INSPECTION_DATE'] = pd.to_datetime(merged_df['INSPECTION_DATE'])\n",
    "\n",
    "# Find the oldest and newest dates\n",
    "oldest_date = merged_df['INSPECTION_DATE'].min()\n",
    "newest_date = merged_df['INSPECTION_DATE'].max()\n",
    "\n",
    "# Create the message\n",
    "message5 = f'contains {num_rows} rows. Oldest Date: {oldest_date}. Newest Date: {newest_date}'\n",
    "print(message5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3f7727-1e90-4ca2-8a68-4aa7cec256e8",
   "metadata": {},
   "source": [
    "<h1>Merge IMD</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fb68d63-0906-4d5c-a27d-2faaab103100",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_df = merged_df.merge(imd_dec, on='lsoa11', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125bc48f-0972-40eb-adb5-5264de8b6298",
   "metadata": {},
   "source": [
    "<h2>Checkpoint - IMD</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "834276df-8cfc-4249-a804-3bd6fa21909d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains 1202805 rows. Oldest Date: 2000-02-10 00:00:00. Newest Date: 2023-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of rows\n",
    "num_rows = len(merged_df)\n",
    "\n",
    "merged_df['INSPECTION_DATE'] = pd.to_datetime(merged_df['INSPECTION_DATE'])\n",
    "\n",
    "# Find the oldest and newest dates\n",
    "oldest_date = merged_df['INSPECTION_DATE'].min()\n",
    "newest_date = merged_df['INSPECTION_DATE'].max()\n",
    "\n",
    "# Create the message\n",
    "message6 = f'contains {num_rows} rows. Oldest Date: {oldest_date}. Newest Date: {newest_date}'\n",
    "print(message6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33d2082-a72f-46bb-8a41-c285d01e3f4a",
   "metadata": {},
   "source": [
    "<h1>Filter by Property Type</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1d7a039-b98b-4152-8c56-22af1595c3f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filter date and type\n",
    "\n",
    "property_types = ['D1 Non-residential Institutions - Community/Day Centre', 'Community/day centre', 'Non-residential Institutions: Community/Day Centre']\n",
    "merged_df = merged_df[merged_df['PROPERTY_TYPE'].isin(property_types)].copy()  # Make a copy of the filtered DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe5b50-381d-402e-87c3-c2c9bfe24220",
   "metadata": {},
   "source": [
    "<h2>Checkpoint - Property Type</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "361657b5-baee-4221-b937-f4143a87146b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains 13415 rows. Oldest Date: 2007-12-24 00:00:00. Newest Date: 2023-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of rows\n",
    "num_rows = len(merged_df)\n",
    "\n",
    "merged_df['INSPECTION_DATE'] = pd.to_datetime(merged_df['INSPECTION_DATE'])\n",
    "\n",
    "# Find the oldest and newest dates\n",
    "oldest_date = merged_df['INSPECTION_DATE'].min()\n",
    "newest_date = merged_df['INSPECTION_DATE'].max()\n",
    "\n",
    "# Create the message\n",
    "message7 = f'contains {num_rows} rows. Oldest Date: {oldest_date}. Newest Date: {newest_date}'\n",
    "print(message7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0abad97-9a79-44b5-996c-215a9053fc46",
   "metadata": {},
   "source": [
    "<h1>Filtering most recent</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f471f6c-f367-4da2-a40f-2263e7155ba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'INSPECTION_DATE' column to datetime\n",
    "merged_df['INSPECTION_DATE'] = pd.to_datetime(merged_df['INSPECTION_DATE'])\n",
    " \n",
    "# Sort the DataFrame by 'INSPECTION_DATE' in descending order\n",
    "merged_df = merged_df.sort_values(by='INSPECTION_DATE', ascending=False)\n",
    "\n",
    "# Drop duplicates in the 'BUILDING_REFERENCE_NUMBER' column, keeping only the first occurrence (most recent date)\n",
    "merged_df = merged_df.drop_duplicates(subset='BUILDING_REFERENCE_NUMBER', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91522b5d-613e-4906-8c0f-65136a8ec3e7",
   "metadata": {},
   "source": [
    "<h2>Checkpoint - most recent filter</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb687129-0e2c-453d-894d-21b6e0c3a72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains 12985 rows. Oldest Date: 2007-12-24 00:00:00. Newest Date: 2023-09-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of rows\n",
    "num_rows = len(merged_df)\n",
    "\n",
    "merged_df['INSPECTION_DATE'] = pd.to_datetime(merged_df['INSPECTION_DATE'])\n",
    "\n",
    "# Find the oldest and newest dates\n",
    "oldest_date = merged_df['INSPECTION_DATE'].min()\n",
    "newest_date = merged_df['INSPECTION_DATE'].max()\n",
    "\n",
    "# Create the message\n",
    "message8 = f'contains {num_rows} rows. Oldest Date: {oldest_date}. Newest Date: {newest_date}'\n",
    "print(message8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e9186-829b-47bb-bb24-65935aa64a5d",
   "metadata": {},
   "source": [
    "<h1>Filter Time Cut off</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e5aef67b-10b0-4410-8aa4-4f2c9019a183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter out rows with 'INSPECTION_DATE' after June 30, 2023\n",
    "cutoff_date = pd.to_datetime('2023-06-30')\n",
    "merged_df = merged_df[merged_df['INSPECTION_DATE'] <= cutoff_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4eeda-e127-4988-9677-69717231a617",
   "metadata": {},
   "source": [
    "<h2>Checkpoint - Final</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "740db9bc-fdfc-46d4-82a2-eff954e528e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains 12745 rows. Oldest Date: 2007-12-24 00:00:00. Newest Date: 2023-06-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of rows\n",
    "num_rows = len(merged_df)\n",
    "\n",
    "merged_df['INSPECTION_DATE'] = pd.to_datetime(merged_df['INSPECTION_DATE'])\n",
    "\n",
    "# Find the oldest and newest dates\n",
    "oldest_date = merged_df['INSPECTION_DATE'].min()\n",
    "newest_date = merged_df['INSPECTION_DATE'].max()\n",
    "\n",
    "# Create the message\n",
    "message9 = f'contains {num_rows} rows. Oldest Date: {oldest_date}. Newest Date: {newest_date}'\n",
    "print(message9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "586db07b-ddc7-4950-b0db-62d1b2230f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains 1308301 rows. Oldest Date: 2000-02-10 00:00:00. Newest Date: 2023-09-30 00:00:00\n",
      "contains 1308301 rows. Oldest Date: 2000-02-10 00:00:00. Newest Date: 2023-09-30 00:00:00\n",
      "contains 1246391 rows. Oldest Date: 2000-02-10 00:00:00. Newest Date: 2023-09-30 00:00:00\n",
      "contains 1202805 rows. Oldest Date: 2000-02-10 00:00:00. Newest Date: 2023-09-30 00:00:00\n",
      "contains 1202805 rows. Oldest Date: 2000-02-10 00:00:00. Newest Date: 2023-09-30 00:00:00\n",
      "contains 1202805 rows. Oldest Date: 2000-02-10 00:00:00. Newest Date: 2023-09-30 00:00:00\n",
      "contains 13415 rows. Oldest Date: 2007-12-24 00:00:00. Newest Date: 2023-09-30 00:00:00\n",
      "contains 12985 rows. Oldest Date: 2007-12-24 00:00:00. Newest Date: 2023-09-30 00:00:00\n",
      "contains 12745 rows. Oldest Date: 2007-12-24 00:00:00. Newest Date: 2023-06-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(message1)\n",
    "print(message2)\n",
    "print(message3)\n",
    "print(message4)\n",
    "print(message5)\n",
    "print(message6)\n",
    "print(message7)\n",
    "print(message8)\n",
    "print(message9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14032f58-985f-4a98-94e3-7a646be43245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_new = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8dab4ee-1c52-49aa-8fce-7e3a06224326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_old = pd.read_excel(r\"C:\\Users\\Elisha.Zissman\\Social Investment Business\\Team_Learning&Influence - Documents\\Data Projects\\EPC - ez - oh\\Community EPCs project\\epc_community_buildings.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98b05a56-fee2-4afa-b0af-2f1ed2f73481",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify the new rows based on a specific column\n",
    "#unique_column = 'BUILDING_REFERENCE_NUMBER'  # Replace with the actual column name you want to use\n",
    "\n",
    "# Extract the values of the unique column from both DataFrames\n",
    "#old_values = set(data_old[unique_column])\n",
    "#new_values = set(data_new[unique_column])\n",
    "\n",
    "# Find the values that are in new_values but not in old_values\n",
    "#new_unique_values = new_values - old_values\n",
    "\n",
    "# Create a DataFrame containing the new rows based on the unique column\n",
    "#new_rows = data_new[data_new[unique_column].isin(new_unique_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27f05d14-1c61-41f5-a501-bcc38e0d45d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#new_rows_BRN = new_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44c17939-2c55-4e9b-ae10-a2106ea5a6d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify the new rows based on a specific column\n",
    "#unique_column = 'LMK_KEY'  # Replace with the actual column name you want to use\n",
    "\n",
    "# Extract the values of the unique column from both DataFrames\n",
    "#old_values = set(data_old[unique_column])\n",
    "#new_values = set(data_new[unique_column])\n",
    "\n",
    "# Find the values that are in new_values but not in old_values\n",
    "#new_unique_values = new_values - old_values\n",
    "\n",
    "# Create a DataFrame containing the new rows based on the unique column\n",
    "#new_rows = data_new[data_new[unique_column].isin(new_unique_values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "837a3314-b27d-4534-87e2-2c7b5ae36a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_old = data_old.rename(columns={'LMK_KEY_x':'LMK_KEY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20a8a25b-46f8-4d0d-ad57-096723748ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#new_rows_LMK = new_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec40fc88-52c9-4b5b-8a14-a29e213944f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#new_rows_LMK.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "165e97ff-32e8-446f-a48d-973bc3e88784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f9cf047-0362-4620-aa9f-b60d8a4a1ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df = new_rows_LMK\n",
    "\n",
    "# Assuming you have a DataFrame named 'df' and the column name is 'country code'\n",
    "#df = df[~df['rgn'].str.startswith(('W', 'S'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "66af45ca-c477-4931-96e2-0938a0908b6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad30d42c-e387-4dc7-bcf2-4f9aecb797fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df = new_rows_BRN\n",
    "\n",
    "# Assuming you have a DataFrame named 'df' and the column name is 'country code'\n",
    "#df = df[~df['rgn'].str.startswith(('W', 'S'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a504a51e-8f87-4672-92a7-b1a0e545c63c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d560e558-e6b0-4e0b-8cc7-f68111bb4efa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
